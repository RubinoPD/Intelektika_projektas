# A grid-based environment with obstacles, rewards, and penalties.

# Project Structure
```
Projektas/
    â”œâ”€â”€ main.py               # Main entry point for the application
    â”œâ”€â”€ environment.py        # Environment implementation
    â”œâ”€â”€ agent.py              # Q-learning agent implementation
    â”œâ”€â”€ visualization.py      # Visualization components
    â”œâ”€â”€ utils.py              # Utility functions
    â””â”€â”€ README.md             # Project documentation
```

# Projekto apÅ¾valga
Å is projektas sukurtas kaip dirbtinio intelekto mokymosi uÅ¾duotis, kurios tikslas - Ä¯gyvendinti pastiprinamojo mokymosi algoritmÄ… realioje aplinkoje ir stebÄ—ti jo mokymosi procesÄ…. Pagrindiniai komponentai:

- **Aplinka**: Tinklelio pasaulis su kliÅ«timis ir baudomis
- **Agentas**: Q-mokymosi algoritmas su epsilon-godÅ¾ia veiksmo parinkimo strategija
- **Vizualizacija**: Realaus laiko animacija, parodanti agento mokymosi procesÄ…

# ğŸš€ Ä®diegimas
## Reikalavimai

- Python 3.7+
- NumPy
- Pygame
- Matplotlib
# Diegimo Å¾ingsniai
1. Klonuokite repozitorijÄ…:
bash
```
git clone https://github.com/RubinoPD/Intelektika_projektas.git
```
2. Pereikite Ä¯ projekto katalogÄ…:
```
cd Intelektika_projektas
```
3. Ä®diekite reikalingas bibliotekas:
```
pip install numpy pygame matplotlib
```
# ğŸ® Naudojimas
ProgramÄ… paleiskite komanda:
```
python main.py
```
# âš™ï¸ ParametrÅ³ konfigÅ«racija
Programos parametrus galite keisti main.py faile:
```
# Aplinkos parametrai
env = GridWorld(
    width=10,               # Tinklelio plotis
    height=10,              # Tinklelio aukÅ¡tis
    obstacle_density=0.2,   # KliÅ«ÄiÅ³ tankis
    penalty_density=0.1,    # BaudÅ³ tankis
    max_steps=100           # Maksimalus Å¾ingsniÅ³ skaiÄius
)

# Agento parametrai
agent = QLearningAgent(
    num_states=env.get_num_states(),
    num_actions=env.get_num_actions(),
    learning_rate=0.1,      # Mokymosi koeficientas
    discount_factor=0.9,    # Nuolaidos faktorius
    exploration_rate=1.0,   # Pradinis tyrinÄ—jimo koeficientas
    min_exploration_rate=0.01, # Minimalus tyrinÄ—jimo koeficientas
    exploration_decay=0.995 # TyrinÄ—jimo koeficiento maÅ¾Ä—jimo greitis
)
```
# ğŸ“Š RezultatÅ³ analizÄ—
Po mokymosi proceso galite analizuoti rezultatus naudodami iÅ¡saugotÄ… Q-lentelÄ™:
```
import numpy as np
import matplotlib.pyplot as plt

# Ä®kelti Q-table
q_table = np.load('q_table.npy')

# Vizualizuoti Q-vertes
plt.figure(figsize=(10, 8))
plt.imshow(q_table, cmap='viridis')
plt.colorbar(label='Q-value')
plt.title('Q-value matrix')
plt.xlabel('Actions')
plt.ylabel('States')
plt.show()
```
----
Projektas sukurtas kaip Intelektikos kurso darbas.